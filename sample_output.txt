runfile('E:/Studies/Ph.D/Sem 4/CSCE 619/SemEval2018Task/twitter_sentiment_titli.py', wdir='E:/Studies/Ph.D/Sem 4/CSCE 619/SemEval2018Task')
C:\Users\Titli\Anaconda3\lib\site-packages\h5py\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
C:\Users\Titli\Anaconda3\lib\site-packages\gensim\utils.py:1167: UserWarning: detected Windows; aliasing chunkize to chunkize_serial
  warnings.warn("detected Windows; aliasing chunkize to chunkize_serial")
Load word2vec done!
Processed file: EI-reg-En-full-train.csv
Processed file: EI-reg-En-full-dev.csv
Processed file: EI-reg-En-part-test.csv
Train shape: 7102 7102
Validation shape: 1464 1464
Test shape: 2000 2000
Max twitter length: 23
Train embedding shape: (7102, 23, 100) (7102,)
Dev embedding shape: (1464, 23, 100) (1464,)
Test embedding shape: (2000, 23, 100) (2000,)
Number of output classes: 4
One-hot encoded labels shape (train, validation, test): (7102, 4) (1464, 4) (2000, 4)
Training size: (8566, 23, 100)
Test size: (2000, 23, 100)


Running LSTM model.......
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, None, 100)         0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 64)                42240     
_________________________________________________________________
dropout_1 (Dropout)          (None, 64)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 4)                 260       
=================================================================
Total params: 42,500
Trainable params: 42,500
Non-trainable params: 0
_________________________________________________________________
Train on 8566 samples, validate on 2000 samples
Epoch 1/20
8566/8566 [==============================] - 3s 345us/step - loss: 1.3644 - acc: 0.3242 - val_loss: 1.3406 - val_acc: 0.3395

Epoch 00001: val_loss improved from inf to 1.34064, saving model to twitter-emotion-lstm.h5
Epoch 2/20
8566/8566 [==============================] - 2s 207us/step - loss: 1.2609 - acc: 0.4335 - val_loss: 1.2773 - val_acc: 0.4155

Epoch 00002: val_loss improved from 1.34064 to 1.27732, saving model to twitter-emotion-lstm.h5
Epoch 3/20
8566/8566 [==============================] - 2s 232us/step - loss: 1.1751 - acc: 0.4947 - val_loss: 1.2370 - val_acc: 0.4435

Epoch 00003: val_loss improved from 1.27732 to 1.23698, saving model to twitter-emotion-lstm.h5
Epoch 4/20
8566/8566 [==============================] - 2s 205us/step - loss: 1.1229 - acc: 0.5279 - val_loss: 1.2241 - val_acc: 0.4605

Epoch 00004: val_loss improved from 1.23698 to 1.22407, saving model to twitter-emotion-lstm.h5
Epoch 5/20
8566/8566 [==============================] - 2s 209us/step - loss: 1.0950 - acc: 0.5403 - val_loss: 1.2261 - val_acc: 0.4640

Epoch 00005: val_loss did not improve
Epoch 6/20
8566/8566 [==============================] - 2s 220us/step - loss: 1.0683 - acc: 0.5604 - val_loss: 1.2278 - val_acc: 0.4660

Epoch 00006: val_loss did not improve
Epoch 7/20
8566/8566 [==============================] - 2s 192us/step - loss: 1.0459 - acc: 0.5698 - val_loss: 1.2779 - val_acc: 0.4460

Epoch 00007: val_loss did not improve
Epoch 8/20
8566/8566 [==============================] - 2s 184us/step - loss: 1.0338 - acc: 0.5767 - val_loss: 1.2317 - val_acc: 0.4740

Epoch 00008: val_loss did not improve
Epoch 9/20
8566/8566 [==============================] - 2s 187us/step - loss: 1.0084 - acc: 0.5878 - val_loss: 1.2339 - val_acc: 0.4720

Epoch 00009: val_loss did not improve
Epoch 10/20
8566/8566 [==============================] - 2s 207us/step - loss: 0.9805 - acc: 0.6041 - val_loss: 1.2501 - val_acc: 0.4730

Epoch 00010: val_loss did not improve
Epoch 11/20
8566/8566 [==============================] - 2s 183us/step - loss: 0.9673 - acc: 0.6067 - val_loss: 1.2359 - val_acc: 0.4830

Epoch 00011: val_loss did not improve
Epoch 12/20
8566/8566 [==============================] - 2s 185us/step - loss: 0.9444 - acc: 0.6162 - val_loss: 1.2478 - val_acc: 0.4860

Epoch 00012: val_loss did not improve
Epoch 13/20
8566/8566 [==============================] - 2s 194us/step - loss: 0.9239 - acc: 0.6289 - val_loss: 1.2662 - val_acc: 0.4840

Epoch 00013: val_loss did not improve
Epoch 14/20
8566/8566 [==============================] - 2s 198us/step - loss: 0.8999 - acc: 0.6410 - val_loss: 1.2451 - val_acc: 0.4875

Epoch 00014: val_loss did not improve
Epoch 15/20
8566/8566 [==============================] - 2s 185us/step - loss: 0.8731 - acc: 0.6558 - val_loss: 1.2903 - val_acc: 0.4870

Epoch 00015: val_loss did not improve
Epoch 16/20
8566/8566 [==============================] - 2s 210us/step - loss: 0.8445 - acc: 0.6646 - val_loss: 1.2824 - val_acc: 0.4865

Epoch 00016: val_loss did not improve
Epoch 17/20
8566/8566 [==============================] - 2s 234us/step - loss: 0.8187 - acc: 0.6752 - val_loss: 1.2770 - val_acc: 0.4960

Epoch 00017: val_loss did not improve
Epoch 18/20
8566/8566 [==============================] - 2s 184us/step - loss: 0.7997 - acc: 0.6848 - val_loss: 1.3050 - val_acc: 0.4900

Epoch 00018: val_loss did not improve
Epoch 19/20
8566/8566 [==============================] - 2s 186us/step - loss: 0.7725 - acc: 0.6992 - val_loss: 1.3430 - val_acc: 0.4870

Epoch 00019: val_loss did not improve
Epoch 20/20
8566/8566 [==============================] - 2s 193us/step - loss: 0.7561 - acc: 0.7045 - val_loss: 1.2961 - val_acc: 0.4905

Epoch 00020: val_loss did not improve

Confusion Matrix on test data [(4x4) for 4 output labels of 'anger', 'fear', 'joy', 'sadness']: 
[[213 121  34 132]
 [ 70 258  35 138]
 [ 37  88 265 111]
 [ 71 128  54 245]]
n [2]: runfile('E:/Studies/Ph.D/Sem 4/CSCE 619/SemEval2018Task/twitter_sentiment_titli.py', wdir='E:/Studies/Ph.D/Sem 4/CSCE 619/SemEval2018Task')
Load word2vec done!
Processed file: EI-reg-En-full-train.csv
Processed file: EI-reg-En-full-dev.csv
Processed file: EI-reg-En-part-test.csv
Train shape: 7102 7102
Validation shape: 1464 1464
Test shape: 2000 2000
Max twitter length: 23
Train embedding shape: (7102, 23, 100) (7102,)
Dev embedding shape: (1464, 23, 100) (1464,)
Test embedding shape: (2000, 23, 100) (2000,)
Number of output classes: 4
One-hot encoded labels shape (train, validation, test): (7102, 4) (1464, 4) (2000, 4)
Training size: (8566, 23, 100)
Test size: (2000, 23, 100)


Running bi-LSTM model.......
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         (None, None, 100)         0         
_________________________________________________________________
bidirectional_1 (Bidirection (None, 128)               84480     
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 4)                 516       
=================================================================
Total params: 84,996
Trainable params: 84,996
Non-trainable params: 0
_________________________________________________________________
Train on 8566 samples, validate on 2000 samples
Epoch 1/20
8566/8566 [==============================] - 7s 826us/step - loss: 1.3514 - acc: 0.3378 - val_loss: 1.3160 - val_acc: 0.3925

Epoch 00001: val_loss improved from inf to 1.31601, saving model to twitter-emotion-bi_lstm.h5
Epoch 2/20
8566/8566 [==============================] - 4s 484us/step - loss: 1.2186 - acc: 0.4713 - val_loss: 1.2486 - val_acc: 0.4430

Epoch 00002: val_loss improved from 1.31601 to 1.24859, saving model to twitter-emotion-bi_lstm.h5
Epoch 3/20
8566/8566 [==============================] - 4s 493us/step - loss: 1.1254 - acc: 0.5252 - val_loss: 1.2546 - val_acc: 0.4580

Epoch 00003: val_loss did not improve
Epoch 4/20
8566/8566 [==============================] - 4s 503us/step - loss: 1.0749 - acc: 0.5534 - val_loss: 1.2407 - val_acc: 0.4595

Epoch 00004: val_loss improved from 1.24859 to 1.24074, saving model to twitter-emotion-bi_lstm.h5
Epoch 5/20
8566/8566 [==============================] - 4s 487us/step - loss: 1.0433 - acc: 0.5682 - val_loss: 1.2314 - val_acc: 0.4615

Epoch 00005: val_loss improved from 1.24074 to 1.23142, saving model to twitter-emotion-bi_lstm.h5
Epoch 6/20
8566/8566 [==============================] - 4s 514us/step - loss: 1.0073 - acc: 0.5883 - val_loss: 1.2506 - val_acc: 0.4660

Epoch 00006: val_loss did not improve
Epoch 7/20
8566/8566 [==============================] - 4s 500us/step - loss: 0.9777 - acc: 0.6020 - val_loss: 1.2618 - val_acc: 0.4730

Epoch 00007: val_loss did not improve
Epoch 8/20
8566/8566 [==============================] - 4s 484us/step - loss: 0.9531 - acc: 0.6117 - val_loss: 1.2603 - val_acc: 0.4735

Epoch 00008: val_loss did not improve
Epoch 9/20
8566/8566 [==============================] - 4s 493us/step - loss: 0.9050 - acc: 0.6364 - val_loss: 1.2978 - val_acc: 0.4665

Epoch 00009: val_loss did not improve
Epoch 10/20
8566/8566 [==============================] - 4s 485us/step - loss: 0.8698 - acc: 0.6584 - val_loss: 1.2920 - val_acc: 0.4880

Epoch 00010: val_loss did not improve
Epoch 11/20
8566/8566 [==============================] - 4s 475us/step - loss: 0.8248 - acc: 0.6755 - val_loss: 1.2783 - val_acc: 0.4955

Epoch 00011: val_loss did not improve
Epoch 12/20
8566/8566 [==============================] - 4s 476us/step - loss: 0.7911 - acc: 0.6957 - val_loss: 1.2796 - val_acc: 0.4990

Epoch 00012: val_loss did not improve
Epoch 13/20
8566/8566 [==============================] - 4s 486us/step - loss: 0.7482 - acc: 0.7084 - val_loss: 1.3558 - val_acc: 0.4875

Epoch 00013: val_loss did not improve
Epoch 14/20
8566/8566 [==============================] - 4s 487us/step - loss: 0.7172 - acc: 0.7229 - val_loss: 1.3633 - val_acc: 0.4990

Epoch 00014: val_loss did not improve
Epoch 15/20
8566/8566 [==============================] - 4s 480us/step - loss: 0.6781 - acc: 0.7385 - val_loss: 1.3635 - val_acc: 0.4950

Epoch 00015: val_loss did not improve
Epoch 16/20
8566/8566 [==============================] - 4s 490us/step - loss: 0.6638 - acc: 0.7431 - val_loss: 1.3467 - val_acc: 0.5105

Epoch 00016: val_loss did not improve
Epoch 17/20
8566/8566 [==============================] - 4s 467us/step - loss: 0.6197 - acc: 0.7627 - val_loss: 1.4281 - val_acc: 0.5045

Epoch 00017: val_loss did not improve
Epoch 18/20
8566/8566 [==============================] - 4s 475us/step - loss: 0.5967 - acc: 0.7752 - val_loss: 1.4886 - val_acc: 0.5055

Epoch 00018: val_loss did not improve
Epoch 19/20
8566/8566 [==============================] - 4s 469us/step - loss: 0.5773 - acc: 0.7771 - val_loss: 1.4769 - val_acc: 0.5000

Epoch 00019: val_loss did not improve
Epoch 20/20
8566/8566 [==============================] - 4s 486us/step - loss: 0.5455 - acc: 0.7910 - val_loss: 1.5209 - val_acc: 0.5030

Epoch 00020: val_loss did not improve

Confusion Matrix on test data [(4x4) for 4 output labels of 'anger', 'fear', 'joy', 'sadness']: 
[[192 162  77  69]
 [ 58 303  63  77]
 [ 23 112 327  39]
 [ 58 173  83 184]]

